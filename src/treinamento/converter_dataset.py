"""
Converte o dataset de pacientes (data/dataset_nifti/) para o formato nnU-Net.

Estrutura de entrada (por paciente):
    data/dataset_nifti/<Paciente>/
        â”œâ”€â”€ preop_ct.nii.gz      â† volume de TC
        â””â”€â”€ lesao.nii.gz         â† mÃ¡scara binÃ¡ria (0=normal, 1=lesÃ£o)

Estrutura de saÃ­da (formato nnU-Net):
    data/nnunet/Dataset001_BoneLesions/
        â”œâ”€â”€ dataset.json
        â”œâ”€â”€ imagesTr/
        â”‚   â””â”€â”€ bone_001_0000.nii.gz  (sufixo _0000 = canal 0 = CT)
        â”œâ”€â”€ labelsTr/
        â”‚   â””â”€â”€ bone_001.nii.gz
        â””â”€â”€ imagesTs/
            â””â”€â”€ bone_XXX_0000.nii.gz  (pacientes sem mÃ¡scara)

Uso:
    python converter_dataset.py
    python converter_dataset.py --dataset-id 1 --split 0.8
"""

import argparse
import json
import shutil
from pathlib import Path

# ---------------------------------------------------------------------------
# Constantes
# ---------------------------------------------------------------------------
SCRIPT_DIR   = Path(__file__).parent.resolve()   # src/treinamento/
PROJECT_ROOT = SCRIPT_DIR.parent.parent           # modelo_ia/
DATA_DIR     = PROJECT_ROOT / "data"
NIFTI_DIR    = DATA_DIR / "dataset_nifti"


def converter_dataset(dataset_id: int = 1, split_treino: float = 0.8,
                      nome: str = "BoneLesions") -> Path:
    """
    Converte dataset_nifti/ â†’ nnunet/Dataset{id:03d}_{nome}/.

    Args:
        dataset_id:    ID numÃ©rico do dataset (padrÃ£o: 1)
        split_treino:  FraÃ§Ã£o de pacientes para treino (restante vai para imagesTs)
        nome:          Nome do dataset nnU-Net
    Returns:
        Caminho para a pasta raiz do dataset nnU-Net gerado
    """
    nome_dataset = f"Dataset{dataset_id:03d}_{nome}"
    saida_dir    = DATA_DIR / "nnunet" / nome_dataset

    imagens_tr = saida_dir / "imagesTr"
    labels_tr  = saida_dir / "labelsTr"
    imagens_ts = saida_dir / "imagesTs"

    for d in [imagens_tr, labels_tr, imagens_ts]:
        d.mkdir(parents=True, exist_ok=True)

    print(f"ğŸ“ Criando dataset: {nome_dataset}")
    print(f"   Origem : {NIFTI_DIR}")
    print(f"   Destino: {saida_dir}")

    # Coleta pacientes
    pacientes = sorted([p for p in NIFTI_DIR.iterdir() if p.is_dir()])
    print(f"\nğŸ‘¥ Pacientes encontrados: {len(pacientes)}")

    com_mascara    = [(p, p/"lesao.nii.gz") for p in pacientes if (p/"lesao.nii.gz").exists()]
    sem_mascara    = [p for p in pacientes if not (p/"lesao.nii.gz").exists()]

    print(f"   Com mÃ¡scara (lesao.nii.gz): {len(com_mascara)}")
    print(f"   Sem mÃ¡scara (sÃ³ CT):        {len(sem_mascara)}")

    if not com_mascara:
        print("\nâš ï¸  Nenhum paciente tem lesao.nii.gz!")
        print("   Anote a lesÃ£o no 3D Slicer e salve como lesao.nii.gz na pasta do paciente.")
        print("   Continuando com os CTs sem mÃ¡scara em imagesTs...")

    # â”€â”€ Pacientes COM mÃ¡scara â†’ imagesTr + labelsTr â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    n_treino = max(1, int(len(com_mascara) * split_treino))
    treino   = com_mascara[:n_treino]
    teste_cm = com_mascara[n_treino:]  # resto dos com_mascara vai para Ts

    copiados_tr = 0
    for idx, (pac, mask_path) in enumerate(treino, start=1):
        ct_path = pac / "preop_ct.nii.gz"
        if not ct_path.exists():
            print(f"   âš ï¸  {pac.name}: preop_ct.nii.gz nÃ£o encontrado, pulando.")
            continue

        prefixo = f"bone_{idx:03d}"
        dst_ct   = imagens_tr / f"{prefixo}_0000.nii.gz"
        dst_mask = labels_tr  / f"{prefixo}.nii.gz"

        shutil.copy2(ct_path,   dst_ct)
        shutil.copy2(mask_path, dst_mask)
        print(f"   âœ… Treino  {idx:03d}: {pac.name}")
        copiados_tr += 1

    # â”€â”€ Pacientes SEM mÃ¡scara + resto com mÃ¡scara â†’ imagesTs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ts_pacientes = [(p, p/"preop_ct.nii.gz") for p in sem_mascara] + \
                   [(p, p/"preop_ct.nii.gz") for p, _ in teste_cm]

    copiados_ts = 0
    idx_ts = n_treino + 1
    for pac, ct_path in ts_pacientes:
        if not ct_path.exists():
            print(f"   âš ï¸  {pac.name}: preop_ct.nii.gz nÃ£o encontrado, pulando.")
            continue
        prefixo = f"bone_{idx_ts:03d}"
        dst_ct  = imagens_ts / f"{prefixo}_0000.nii.gz"
        shutil.copy2(ct_path, dst_ct)
        print(f"   ğŸ“‹ Teste   {idx_ts:03d}: {pac.name} (sem mÃ¡scara)")
        copiados_ts += 1
        idx_ts += 1

    # â”€â”€ dataset.json â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    dataset_json = {
        "name":         nome,
        "description":  "SegmentaÃ§Ã£o de lesÃµes Ã³sseas crÃ¢nio-maxilofaciais",
        "tensorImageSize": "3D",
        "reference":    "",
        "licence":      "",
        "release":      "0.1.0",
        "channel_names": {"0": "CT"},
        "labels": {
            "background": 0,
            "lesao":      1
        },
        "numTraining":  copiados_tr,
        "file_ending":  ".nii.gz"
    }

    json_path = saida_dir / "dataset.json"
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(dataset_json, f, indent=2, ensure_ascii=False)

    # â”€â”€ Resumo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f"\n{'=' * 50}")
    print(f"âœ… ConversÃ£o concluÃ­da!")
    print(f"   imagesTr : {copiados_tr} CT(s) com mÃ¡scara")
    print(f"   imagesTs : {copiados_ts} CT(s) sem mÃ¡scara")
    print(f"   dataset.json â†’ {json_path}")
    print(f"\n{'=' * 50}")
    print("ğŸ“Œ PrÃ³ximos passos:")
    print("   1. Comprima a pasta abaixo e suba para o Google Drive:")
    print(f"      {saida_dir}")
    print("   2. Abra o notebook treinar_colab.ipynb no Google Colab")
    print("   3. Ou, se tiver GPU local, rode:")
    print(f"      export nnUNet_raw={saida_dir.parent}")
    print(f"      nnUNetv2_plan_and_preprocess -d {dataset_id:03d} --verify_dataset_integrity")

    return saida_dir


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Converte dataset de pacientes para o formato nnU-Net"
    )
    parser.add_argument("--dataset-id",  type=int,   default=1,
                        help="ID numÃ©rico do dataset (padrÃ£o: 1)")
    parser.add_argument("--split",       type=float, default=0.8,
                        help="FraÃ§Ã£o treino/total (padrÃ£o: 0.8)")
    parser.add_argument("--nome",        type=str,   default="BoneLesions",
                        help="Nome do dataset (padrÃ£o: BoneLesions)")
    args = parser.parse_args()

    converter_dataset(dataset_id=args.dataset_id,
                      split_treino=args.split,
                      nome=args.nome)
